{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a14157-64d2-44ff-9693-9d652966b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43853472-b7b9-4d76-b20d-4b0d94cfed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data 5 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>PAQ605</th>\n",
       "      <th>BMXBMI</th>\n",
       "      <th>LBXGLU</th>\n",
       "      <th>DIQ010</th>\n",
       "      <th>LBXGLT</th>\n",
       "      <th>LBXIN</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73564.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.7</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>14.91</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73568.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73576.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>6.14</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73577.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>16.15</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73580.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>10.92</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEQN  RIAGENDR  PAQ605  BMXBMI  LBXGLU  DIQ010  LBXGLT  LBXIN age_group\n",
       "0  73564.0       2.0     2.0    35.7   110.0     2.0   150.0  14.91     Adult\n",
       "1  73568.0       2.0     2.0    20.3    89.0     2.0    80.0   3.85     Adult\n",
       "2  73576.0       1.0     2.0    23.2    89.0     2.0    68.0   6.14     Adult\n",
       "3  73577.0       1.0     2.0    28.9   104.0     NaN    84.0  16.15     Adult\n",
       "4  73580.0       2.0     1.0    35.9   103.0     2.0    81.0  10.92     Adult"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('Train_Data.csv')\n",
    "print(\"Train Data 5 rows\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25199e7d-f613-4f94-9831-a4877fbd3c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data 5 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>PAQ605</th>\n",
       "      <th>BMXBMI</th>\n",
       "      <th>LBXGLU</th>\n",
       "      <th>DIQ010</th>\n",
       "      <th>LBXGLT</th>\n",
       "      <th>LBXIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>15.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75580.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>15.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73820.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.6</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>8.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80489.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>12.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82047.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEQN  RIAGENDR  PAQ605  BMXBMI  LBXGLU  DIQ010  LBXGLT  LBXIN\n",
       "0  77017.0       1.0     1.0    32.2    96.0     2.0   135.0  15.11\n",
       "1  75580.0       2.0     2.0    26.3   100.0     2.0   141.0  15.26\n",
       "2  73820.0       1.0     2.0    28.6   107.0     2.0   136.0   8.82\n",
       "3  80489.0       2.0     1.0    22.1    93.0     2.0   111.0  12.13\n",
       "4  82047.0       1.0     1.0    24.7    91.0     2.0   105.0   3.12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('Test_Data.csv')\n",
    "print(\"Test Data 5 rows\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5458c41e-6654-48a3-8bd9-7fec6db6a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqn = test_df['SEQN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd80fa31-2589-48e2-91b6-6bc59692a9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data (rows, columns): (1966, 9)\n",
      "Shape of test data (rows, columns): (312, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of training data (rows, columns): {train_df.shape}\")\n",
    "print(f\"Shape of test data (rows, columns): {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa048d3-c134-42b6-9e44-a1e3562dcfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1966 entries, 0 to 1965\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   SEQN       1954 non-null   float64\n",
      " 1   RIAGENDR   1948 non-null   float64\n",
      " 2   PAQ605     1953 non-null   float64\n",
      " 3   BMXBMI     1948 non-null   float64\n",
      " 4   LBXGLU     1953 non-null   float64\n",
      " 5   DIQ010     1948 non-null   float64\n",
      " 6   LBXGLT     1955 non-null   float64\n",
      " 7   LBXIN      1957 non-null   float64\n",
      " 8   age_group  1952 non-null   object \n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 138.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc1d5b36-8f09-4045-9b4d-e31b9493932a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 312 entries, 0 to 311\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   SEQN      310 non-null    float64\n",
      " 1   RIAGENDR  310 non-null    float64\n",
      " 2   PAQ605    311 non-null    float64\n",
      " 3   BMXBMI    311 non-null    float64\n",
      " 4   LBXGLU    311 non-null    float64\n",
      " 5   DIQ010    311 non-null    float64\n",
      " 6   LBXGLT    310 non-null    float64\n",
      " 7   LBXIN     311 non-null    float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8830fa2-4910-4623-8514-dcd45f0ad0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Data Descriptive Statistics ---\n",
      "               SEQN     RIAGENDR       PAQ605       BMXBMI       LBXGLU  \\\n",
      "count   1954.000000  1948.000000  1953.000000  1948.000000  1953.000000   \n",
      "mean   78683.621801     1.510267     1.825397    27.965400    99.491039   \n",
      "std     2924.115709     0.500023     0.399449     7.327616    16.774665   \n",
      "min    73564.000000     1.000000     1.000000    14.500000    63.000000   \n",
      "25%    76194.000000     1.000000     2.000000    22.800000    91.000000   \n",
      "50%    78717.000000     2.000000     2.000000    26.800000    97.000000   \n",
      "75%    81217.000000     2.000000     2.000000    31.300000   104.000000   \n",
      "max    83727.000000     2.000000     7.000000    70.100000   405.000000   \n",
      "\n",
      "            DIQ010       LBXGLT        LBXIN  \n",
      "count  1948.000000  1955.000000  1957.000000  \n",
      "mean      2.015914   115.150384    11.862892  \n",
      "std       0.187579    46.271615     9.756713  \n",
      "min       1.000000    40.000000     0.140000  \n",
      "25%       2.000000    87.000000     5.800000  \n",
      "50%       2.000000   105.000000     9.030000  \n",
      "75%       2.000000   131.000000    14.480000  \n",
      "max       3.000000   604.000000   102.290000  \n",
      "\n",
      "--- Testing Data Descriptive Statistics ---\n",
      "               SEQN    RIAGENDR      PAQ605      BMXBMI      LBXGLU  \\\n",
      "count    310.000000  310.000000  311.000000  311.000000  311.000000   \n",
      "mean   78717.490323    1.522581    1.803859   27.810611  100.067524   \n",
      "std     2905.999069    0.500297    0.397717    6.717031   23.920539   \n",
      "min    73659.000000    1.000000    1.000000   15.900000   69.000000   \n",
      "25%    76006.500000    1.000000    2.000000   22.950000   92.000000   \n",
      "50%    79036.500000    2.000000    2.000000   26.800000   97.000000   \n",
      "75%    81167.000000    2.000000    2.000000   30.900000  103.000000   \n",
      "max    83694.000000    2.000000    2.000000   54.900000  368.000000   \n",
      "\n",
      "           DIQ010      LBXGLT       LBXIN  \n",
      "count  311.000000  310.000000  311.000000  \n",
      "mean     2.019293  114.241935   11.666463  \n",
      "std      0.159477   52.356101    9.570438  \n",
      "min      1.000000   43.000000    1.040000  \n",
      "25%      2.000000   86.000000    6.120000  \n",
      "50%      2.000000  102.500000    9.220000  \n",
      "75%      2.000000  128.750000   14.185000  \n",
      "max      3.000000  510.000000   81.790000  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Training Data Descriptive Statistics ---\")\n",
    "print(train_df.describe())\n",
    "\n",
    "print(\"\\n--- Testing Data Descriptive Statistics ---\")\n",
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94937779-1428-4096-ac9d-937cc48178a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Target Variable Distribution (Before Mapping) ---\n",
      "age_group\n",
      "Adult     1638\n",
      "Senior     314\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Target Variable Distribution (Before Mapping) ---\")\n",
    "print(train_df['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac8eccba-5fa3-4c64-86f9-98adfc599e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each class:\n",
      "age_group\n",
      "Adult     83.913934\n",
      "Senior    16.086066\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of each class:\")\n",
    "print(train_df['age_group'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e902c4b-f514-49c0-843d-3390043b82a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['age_group'] = train_df['age_group'].map({'Adult': 0, 'Senior': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc6895c1-e34d-43f7-83a8-5ca6501654a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Target Variable Distribution (After Mapping) ---\n",
      "age_group\n",
      "0.0    1638\n",
      "1.0     314\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Target Variable Distribution (After Mapping) ---\")\n",
    "print(train_df['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7771f538-5696-48e2-bf3f-d02460d118a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each class:\n",
      "age_group\n",
      "0.0    83.913934\n",
      "1.0    16.086066\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of each class:\")\n",
    "print(train_df['age_group'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f798218-6aae-49d4-bec4-176a048459e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Missing Values in Training Data ---\n",
      "           Missing Count  Missing Percent (%)\n",
      "RIAGENDR              18             0.915565\n",
      "BMXBMI                18             0.915565\n",
      "DIQ010                18             0.915565\n",
      "age_group             14             0.712106\n",
      "PAQ605                13             0.661241\n",
      "LBXGLU                13             0.661241\n",
      "SEQN                  12             0.610376\n",
      "LBXGLT                11             0.559512\n",
      "LBXIN                  9             0.457782\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Missing Values in Training Data ---\")\n",
    "missing_train_count = train_df.isnull().sum()\n",
    "missing_train_percent = (missing_train_count / len(train_df)) * 100\n",
    "missing_train_df = pd.DataFrame({'Missing Count': missing_train_count, 'Missing Percent (%)': missing_train_percent})\n",
    "print(missing_train_df[missing_train_df['Missing Count'] > 0].sort_values(by='Missing Percent (%)', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b75ba6e8-e186-47a7-a7fc-657d9127e868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Missing Values in Test Data ---\n",
      "          Missing Count  Missing Percent (%)\n",
      "SEQN                  2             0.641026\n",
      "RIAGENDR              2             0.641026\n",
      "LBXGLT                2             0.641026\n",
      "PAQ605                1             0.320513\n",
      "BMXBMI                1             0.320513\n",
      "LBXGLU                1             0.320513\n",
      "DIQ010                1             0.320513\n",
      "LBXIN                 1             0.320513\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Missing Values in Test Data ---\")\n",
    "missing_test_count = test_df.isnull().sum()\n",
    "missing_test_percent = (missing_test_count / len(test_df)) * 100\n",
    "missing_test_df = pd.DataFrame({'Missing Count': missing_test_count, 'Missing Percent (%)': missing_test_percent})\n",
    "print(missing_test_df[missing_test_df['Missing Count'] > 0].sort_values(by='Missing Percent (%)', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6faaef1-d1bd-4af9-89df-a211cd4de5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of rows in train_df: 1966\n"
     ]
    }
   ],
   "source": [
    "# --- Data Cleaning: Handling Missing Target Values ---\n",
    "initial_train_rows = train_df.shape[0]\n",
    "print(f\"Initial number of rows in train_df: {initial_train_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3995b16-a836-4e70-b5c6-b6fb7b43a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=['age_group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93376a9b-8969-4da1-9ec6-a5e4e6274319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train_df after dropping missing age_group: 1952\n",
      "Number of rows dropped: 14\n",
      "\n",
      "Missing values in 'age_group' after dropping:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "final_train_rows = train_df.shape[0]\n",
    "print(f\"Number of rows in train_df after dropping missing age_group: {final_train_rows}\")\n",
    "print(f\"Number of rows dropped: {initial_train_rows - final_train_rows}\")\n",
    "print(\"\\nMissing values in 'age_group' after dropping:\")\n",
    "print(train_df['age_group'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be43a72e-db95-46f1-961b-e7d3c7e6669d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Imputing Missing Numerical Features with Median ---\n",
      "  Filled missing values in 'BMXBMI' with median: 26.8\n",
      "  Filled missing values in 'LBXGLU' with median: 97.0\n",
      "  Filled missing values in 'LBXGLT' with median: 105.0\n",
      "  Filled missing values in 'LBXIN' with median: 9.03\n",
      "\n",
      "--- Imputing Missing Categorical Features with Mode ---\n",
      "  Filled missing values in 'RIAGENDR' with mode: 2.0\n",
      "  Filled missing values in 'PAQ605' with mode: 2.0\n",
      "  Filled missing values in 'DIQ010' with mode: 2.0\n",
      "\n",
      "--- Remaining Missing Values (Features) after Imputation (Train/Test) ---\n",
      "Train: \n",
      "SEQN    12\n",
      "dtype: int64\n",
      "Test: \n",
      "SEQN    2\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prathamesh\\AppData\\Local\\Temp\\ipykernel_1904\\3874371451.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\prathamesh\\AppData\\Local\\Temp\\ipykernel_1904\\3874371451.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\prathamesh\\AppData\\Local\\Temp\\ipykernel_1904\\3874371451.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\prathamesh\\AppData\\Local\\Temp\\ipykernel_1904\\3874371451.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(mode_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "numerical_features = ['BMXBMI', 'LBXGLU', 'LBXGLT', 'LBXIN']\n",
    "categorical_features = ['RIAGENDR', 'PAQ605', 'DIQ010']\n",
    "\n",
    "print(\"\\n--- Imputing Missing Numerical Features with Median ---\")\n",
    "for col in numerical_features:\n",
    "    median_val = train_df[col].median()\n",
    "    train_df[col].fillna(median_val, inplace=True)\n",
    "    test_df[col].fillna(median_val, inplace=True)\n",
    "    print(f\"  Filled missing values in '{col}' with median: {median_val}\")\n",
    "\n",
    "print(\"\\n--- Imputing Missing Categorical Features with Mode ---\")\n",
    "for col in categorical_features:\n",
    "    mode_val = train_df[col].mode()[0]\n",
    "    train_df[col].fillna(mode_val, inplace=True)\n",
    "    test_df[col].fillna(mode_val, inplace=True)\n",
    "    print(f\"  Filled missing values in '{col}' with mode: {mode_val}\")\n",
    "\n",
    "print(\"\\n--- Remaining Missing Values (Features) after Imputation (Train/Test) ---\")\n",
    "print(f\"Train: \\n{train_df.isnull().sum()[train_df.isnull().sum() > 0]}\")\n",
    "print(f\"Test: \\n{test_df.isnull().sum()[test_df.isnull().sum() > 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "687a4e45-da4a-4947-b3cd-f86bc43dd566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Applying One-Hot Encoding ---\n",
      "One-hot encoding applied to training and test data.\n"
     ]
    }
   ],
   "source": [
    "# --- Feature Engineering: One-Hot Encoding Categorical Variables ---\n",
    "\n",
    "categorical_features_to_encode = ['RIAGENDR', 'PAQ605', 'DIQ010']\n",
    "\n",
    "print(\"\\n--- Applying One-Hot Encoding ---\")\n",
    "train_df = pd.get_dummies(train_df, columns=categorical_features_to_encode, drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=categorical_features_to_encode, drop_first=True)\n",
    "print(\"One-hot encoding applied to training and test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fef786c2-d0b7-4427-a1fc-6f10948fb660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Column Alignment Check & Correction ---\n",
      "  Adding missing columns to test_df: ['PAQ605_7.0']\n",
      "  test_df columns aligned and ordered to match train_df features.\n",
      "\n",
      "Final feature counts after alignment: Train=9, Test=9\n",
      "Are feature columns identical in train and test? True\n"
     ]
    }
   ],
   "source": [
    "train_features_for_alignment = train_df.drop(columns=['age_group', 'SEQN']).columns\n",
    "test_features_for_alignment = test_df.drop(columns=['SEQN']).columns # Only drop SEQN from test for alignment check\n",
    "\n",
    "print(\"\\n--- Column Alignment Check & Correction ---\")\n",
    "missing_in_test = set(train_features_for_alignment) - set(test_features_for_alignment)\n",
    "missing_in_train = set(test_features_for_alignment) - set(train_features_for_alignment)\n",
    "\n",
    "if missing_in_test:\n",
    "    print(f\"  Adding missing columns to test_df: {list(missing_in_test)}\")\n",
    "    for col in missing_in_test:\n",
    "        test_df[col] = 0\n",
    "if missing_in_train:\n",
    "    print(f\"  Dropping extra columns from test_df: {list(missing_in_train)}\")\n",
    "    test_df.drop(columns=list(missing_in_train), inplace=True)\n",
    "\n",
    "test_df = test_df[train_features_for_alignment]\n",
    "print(\"  test_df columns aligned and ordered to match train_df features.\")\n",
    "\n",
    "print(f\"\\nFinal feature counts after alignment: Train={train_df.drop(columns=['age_group', 'SEQN']).shape[1]}, Test={test_df.shape[1]}\")\n",
    "print(f\"Are feature columns identical in train and test? {list(train_df.drop(columns=['age_group', 'SEQN']).columns) == list(test_df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37650286-1da1-48bf-aafb-740097989735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Training: Prepare Data and Train a Baseline Model ---\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89740878-c034-42f2-a7da-d5325cc6d7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train (features for training): (1952, 9)\n",
      "Shape of y_train (target for training): (1952,)\n",
      "Shape of X_test (features for prediction): (312, 9)\n"
     ]
    }
   ],
   "source": [
    "# Preparing Data for Modeling\n",
    "X_train = train_df.drop(columns=['age_group', 'SEQN'])\n",
    "y_train = train_df['age_group']\n",
    "\n",
    "X_test = test_df\n",
    "\n",
    "print(f\"Shape of X_train (features for training): {X_train.shape}\")\n",
    "print(f\"Shape of y_train (target for training): {y_train.shape}\")\n",
    "print(f\"Shape of X_test (features for prediction): {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2d550c6-ef6b-43d4-aa29-53cec6da4f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Logistic Regression Model ---\n",
      "Logistic Regression Model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Training the Baseline Model: Logistic Regression ---\n",
    "print(\"\\n--- Training Logistic Regression Model ---\")\n",
    "\n",
    "model_lr = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced')\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Logistic Regression Model trained successfully.\")\n",
    "y_train_pred_lr = model_lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aa07bdf-c07e-4152-9fcc-5e82502317a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logistic Regression Model Evaluation on Training Data ---\n",
      "Training F1 Score: 0.4256\n",
      "\n",
      "Classification Report (Training Data):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Adult (0)       0.92      0.73      0.81      1638\n",
      "  Senior (1)       0.31      0.66      0.43       314\n",
      "\n",
      "    accuracy                           0.72      1952\n",
      "   macro avg       0.62      0.69      0.62      1952\n",
      "weighted avg       0.82      0.72      0.75      1952\n",
      "\n",
      "\n",
      "Confusion Matrix (Training Data):\n",
      "[[1190  448]\n",
      " [ 108  206]]\n",
      "\n",
      "Predictions made on test data using Logistic Regression.\n",
      "\n",
      "Distribution of predictions on test data:\n",
      "0.0    217\n",
      "1.0     95\n",
      "Name: count, dtype: int64\n",
      "0.0    69.551282\n",
      "1.0    30.448718\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate the Model's Performance on Training Data ---\n",
    "print(\"\\n--- Logistic Regression Model Evaluation on Training Data ---\")\n",
    "\n",
    "f1_train_lr = f1_score(y_train, y_train_pred_lr)\n",
    "print(f\"Training F1 Score: {f1_train_lr:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Training Data):\")\n",
    "print(classification_report(y_train, y_train_pred_lr, target_names=['Adult (0)', 'Senior (1)']))\n",
    "\n",
    "print(\"\\nConfusion Matrix (Training Data):\")\n",
    "print(confusion_matrix(y_train, y_train_pred_lr))\n",
    "\n",
    "\n",
    "y_test_pred_lr = model_lr.predict(X_test)\n",
    "print(\"\\nPredictions made on test data using Logistic Regression.\")\n",
    "\n",
    "print(\"\\nDistribution of predictions on test data:\")\n",
    "print(pd.Series(y_test_pred_lr).value_counts())\n",
    "print(pd.Series(y_test_pred_lr).value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a7e4e2e-2212-476d-82f2-4af757710231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 314, number of negative: 1638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 761\n",
      "[LightGBM] [Info] Number of data points in the train set: 1952, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160861 -> initscore=-1.651838\n",
      "[LightGBM] [Info] Start training from score -1.651838\n",
      "LightGBM Model trained successfully.\n",
      "\n",
      "--- LightGBM Model Evaluation on Training Data ---\n",
      "Training F1 Score (LightGBM): 0.8418\n",
      "\n",
      "Classification Report (Training Data - LightGBM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Adult (0)       1.00      0.93      0.96      1638\n",
      "  Senior (1)       0.73      1.00      0.84       314\n",
      "\n",
      "    accuracy                           0.94      1952\n",
      "   macro avg       0.86      0.96      0.90      1952\n",
      "weighted avg       0.96      0.94      0.94      1952\n",
      "\n",
      "\n",
      "Confusion Matrix (Training Data - LightGBM):\n",
      "[[1520  118]\n",
      " [   0  314]]\n",
      "\n",
      "Predictions made on test data using LightGBM.\n",
      "\n",
      "Distribution of predictions on test data (LightGBM):\n",
      "0.0    258\n",
      "1.0     54\n",
      "Name: count, dtype: int64\n",
      "0.0    82.692308\n",
      "1.0    17.307692\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- Model Training: LightGBM Classifier ---\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the LightGBM Classifier model.\n",
    "model_lgbm = lgb.LGBMClassifier(objective='binary', metric='f1', is_unbalance=True, random_state=42)\n",
    "\n",
    "model_lgbm.fit(X_train, y_train)\n",
    "\n",
    "print(\"LightGBM Model trained successfully.\")\n",
    "\n",
    "# --- Make Predictions on the Training Data ---\n",
    "y_train_pred_lgbm = model_lgbm.predict(X_train)\n",
    "\n",
    "# --- Evaluate the LightGBM Model's Performance on Training Data ---\n",
    "print(\"\\n--- LightGBM Model Evaluation on Training Data ---\")\n",
    "\n",
    "# Calculate the F1-score for the training data.\n",
    "f1_train_lgbm = f1_score(y_train, y_train_pred_lgbm)\n",
    "print(f\"Training F1 Score (LightGBM): {f1_train_lgbm:.4f}\")\n",
    "\n",
    "# Print the classification report.\n",
    "print(\"\\nClassification Report (Training Data - LightGBM):\")\n",
    "print(classification_report(y_train, y_train_pred_lgbm, target_names=['Adult (0)', 'Senior (1)']))\n",
    "\n",
    "# Print the confusion matrix.\n",
    "print(\"\\nConfusion Matrix (Training Data - LightGBM):\")\n",
    "print(confusion_matrix(y_train, y_train_pred_lgbm))\n",
    "\n",
    "# --- Make Predictions on the Test Data (for submission) ---\n",
    "# Predict the 'age_group' for the unseen test data using the LightGBM model.\n",
    "y_test_pred_lgbm = model_lgbm.predict(X_test)\n",
    "print(\"\\nPredictions made on test data using LightGBM.\")\n",
    "\n",
    "# Display the distribution of predicted classes on the test set.\n",
    "print(\"\\nDistribution of predictions on test data (LightGBM):\")\n",
    "print(pd.Series(y_test_pred_lgbm).value_counts())\n",
    "print(pd.Series(y_test_pred_lgbm).value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f93a90a-c0bc-4154-8e97-7432178a0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Create Submission File ---\n",
    "# submission_df = pd.DataFrame({\n",
    "#     'age_group': y_test_pred_lgbm.astype(int)\n",
    "# })\n",
    "\n",
    "# print(submission_df.head())\n",
    "# print(submission_df.tail())\n",
    "\n",
    "# submission_file_name = 'submission.csv'\n",
    "# submission_df.to_csv(submission_file_name, index=False)\n",
    "\n",
    "# print(f\"\\nSubmission file '{submission_file_name}' created successfully!\")\n",
    "# submission_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62d897b0-6054-4c52-9584-66c64e0f1cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F1 Scores: [0.31111111 0.35114504 0.35294118 0.30075188 0.46969697]\n",
      "Mean CV F1 Score: 0.3571\n",
      "Standard Deviation of CV F1 Scores: 0.0600\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "model_lgbm_cv = lgb.LGBMClassifier(objective='binary', metric='f1', is_unbalance=True, random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(model_lgbm_cv, X_train, y_train, cv=cv, scoring='f1', n_jobs=-1)\n",
    "\n",
    "print(f\"Cross-Validation F1 Scores: {cv_scores}\")\n",
    "print(f\"Mean CV F1 Score: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard Deviation of CV F1 Scores: {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28e4fe2c-9d76-45e4-af6c-d0cbccb9d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameter Tuning: LightGBM with GridSearchCV ---\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold # Added StratifiedKFold import\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "# Define the LightGBM model with the imbalanced handling.\n",
    "model_lgbm_tune = lgb.LGBMClassifier(objective='binary', metric='f1', is_unbalance=True, random_state=42)\n",
    "\n",
    "# Define the range of parameters to search.\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'num_leaves': [20, 31, 40],\n",
    "    'max_depth': [-1, 7, 10],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "969fa4c3-0fb7-454d-8cb0-fdea5c609b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting GridSearchCV for LightGBM Hyperparameter Tuning ---\n",
      "[LightGBM] [Info] Number of positive: 314, number of negative: 1638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 761\n",
      "[LightGBM] [Info] Number of data points in the train set: 1952, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160861 -> initscore=-1.651838\n",
      "[LightGBM] [Info] Start training from score -1.651838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "--- Hyperparameter Tuning Complete ---\n",
      "Best F1 Score found: 0.4068\n",
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 100, 'num_leaves': 20, 'reg_alpha': 0.5, 'reg_lambda': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Starting GridSearchCV for LightGBM Hyperparameter Tuning ---\")\n",
    "\n",
    "# Set up GridSearchCV.\n",
    "grid_search = GridSearchCV(estimator=model_lgbm_tune,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='f1',\n",
    "                           cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "                           n_jobs=-1,\n",
    "                           verbose=0)\n",
    "\n",
    "# Run the grid search on your training data.\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n--- Hyperparameter Tuning Complete ---\")\n",
    "print(f\"Best F1 Score found: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# You can now access the best model directly:\n",
    "best_lgbm_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb502f3f-596c-4e1d-94d8-7d3dc74fc2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Final LightGBM Model with Best Tuned Parameters ---\n",
      "[LightGBM] [Info] Number of positive: 314, number of negative: 1638\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 761\n",
      "[LightGBM] [Info] Number of data points in the train set: 1952, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160861 -> initscore=-1.651838\n",
      "[LightGBM] [Info] Start training from score -1.651838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Final LightGBM Model (tuned) trained successfully.\n",
      "Predictions made on test data using tuned LightGBM model.\n",
      "\n",
      "Submission file 'submission.csv' created successfully with best-tuned model!\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Training Final LightGBM Model with Best Tuned Parameters ---\")\n",
    "X_train = train_df.drop(columns=['age_group', 'SEQN'])\n",
    "y_train = train_df['age_group']\n",
    "X_test = test_df\n",
    "\n",
    "# Initialize the LightGBM Classifier with the BEST PARAMETERS found by GridSearchCV.\n",
    "best_params = {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 100, 'num_leaves': 20, 'reg_alpha': 0.5, 'reg_lambda': 0}\n",
    "\n",
    "model_lgbm_tuned = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    metric='f1',\n",
    "    is_unbalance=True, \n",
    "    random_state=42,   \n",
    "    **best_params      \n",
    ")\n",
    "\n",
    "# Train the model with the best parameters.\n",
    "model_lgbm_tuned.fit(X_train, y_train)\n",
    "\n",
    "print(\"Final LightGBM Model (tuned) trained successfully.\")\n",
    "\n",
    "# --- Make Predictions on the Test Data ---\n",
    "y_test_pred_tuned = model_lgbm_tuned.predict(X_test)\n",
    "print(\"Predictions made on test data using tuned LightGBM model.\")\n",
    "\n",
    "# --- Create Submission File ---\n",
    "submission_df = pd.DataFrame({\n",
    "    'age_group': y_test_pred_tuned.astype(int)\n",
    "})\n",
    "\n",
    "submission_file_name = 'submission.csv'\n",
    "submission_df.to_csv(submission_file_name, index=False)\n",
    "\n",
    "print(f\"\\nSubmission file '{submission_file_name}' created successfully with best-tuned model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a0dc7-9e70-46e8-9b1b-4a9cc746bd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
